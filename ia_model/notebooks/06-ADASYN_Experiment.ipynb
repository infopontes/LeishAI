{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926de29d-bc88-4d14-8435-5c6beb673a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and Preprocessing Data ---\n",
      "--- Data Preprocessing Complete ---\n",
      "Shape of numerical features (X): (456, 43)\n",
      "\n",
      "--- Data Split ---\n",
      "Original positive cases in training set: 109 (29.9%)\n",
      "\n",
      "--- Applying ADASYN within Pipelines ---\n",
      "\n",
      "--- Training Logistic Regression with ADASYN ---\n",
      "\n",
      "--- Logistic Regression (ADASYN) Performance ---\n",
      "Confusion Matrix:\n",
      "[[41 24]\n",
      " [14 13]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.68        65\n",
      "           1       0.35      0.48      0.41        27\n",
      "\n",
      "    accuracy                           0.59        92\n",
      "   macro avg       0.55      0.56      0.54        92\n",
      "weighted avg       0.63      0.59      0.60        92\n",
      "\n",
      "\n",
      "--- Training XGBoost with ADASYN ---\n",
      "\n",
      "--- XGBoost (ADASYN) Performance ---\n",
      "Confusion Matrix:\n",
      "[[44 21]\n",
      " [15 12]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71        65\n",
      "           1       0.36      0.44      0.40        27\n",
      "\n",
      "    accuracy                           0.61        92\n",
      "   macro avg       0.55      0.56      0.55        92\n",
      "weighted avg       0.63      0.61      0.62        92\n",
      "\n",
      "\n",
      "--- ADASYN experiments completed in 0.36 seconds. ---\n"
     ]
    }
   ],
   "source": [
    "# --- ADASYN (Adaptive Synthetic Sampling) Experiment Notebook ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import ADASYN # Import ADASYN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import time\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 1. Load and Preprocess the Data (Our Standard Block) ---\n",
    "# ==============================================================================\n",
    "print(\"--- Loading and Preprocessing Data ---\")\n",
    "\n",
    "# Load the raw dataset\n",
    "file_path = '../data/raw/leish_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Handle Missing Values\n",
    "for col in df_processed.select_dtypes(include=['object']).columns:\n",
    "    df_processed[col] = df_processed[col].fillna('Unknown')\n",
    "\n",
    "# Encode the Target Variable\n",
    "target_map = {'positivo': 1, 'negativo': 0, 'Unknown': 0}\n",
    "df_processed['diagnosis'] = df_processed['diagnosis'].map(target_map).astype(int)\n",
    "\n",
    "# Separate features from the target BEFORE encoding features\n",
    "X_categorical = df_processed.drop('diagnosis', axis=1)\n",
    "y_numeric = df_processed['diagnosis']\n",
    "\n",
    "# Apply One-Hot Encoding to categorical features\n",
    "X_numeric = pd.get_dummies(X_categorical, drop_first=True, dtype=int)\n",
    "\n",
    "print(\"--- Data Preprocessing Complete ---\")\n",
    "print(f\"Shape of numerical features (X): {X_numeric.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 2. Split Data AFTER Preprocessing ---\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_numeric, y_numeric, test_size=0.2, random_state=42, stratify=y_numeric\n",
    ")\n",
    "print(\"\\n--- Data Split ---\")\n",
    "print(f\"Original positive cases in training set: {y_train.sum()} ({y_train.mean()*100:.1f}%)\")\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 3. Define Models and Apply ADASYN using a Pipeline ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Applying ADASYN within Pipelines ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- Model 1: Logistic Regression with ADASYN ---\n",
    "pipeline_logreg_adasyn = ImbPipeline([\n",
    "    ('sampler', ADASYN(random_state=42)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42)) # No class_weight\n",
    "])\n",
    "\n",
    "print(\"\\n--- Training Logistic Regression with ADASYN ---\")\n",
    "pipeline_logreg_adasyn.fit(X_train, y_train)\n",
    "y_pred_logreg_adasyn = pipeline_logreg_adasyn.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Logistic Regression (ADASYN) Performance ---\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg_adasyn))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg_adasyn))\n",
    "\n",
    "# --- Model 2: XGBoost with ADASYN ---\n",
    "pipeline_xgb_adasyn = ImbPipeline([\n",
    "    ('sampler', ADASYN(random_state=42)),\n",
    "    ('classifier', xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        # scale_pos_weight is NOT needed\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"\\n--- Training XGBoost with ADASYN ---\")\n",
    "pipeline_xgb_adasyn.fit(X_train, y_train)\n",
    "y_pred_xgb_adasyn = pipeline_xgb_adasyn.predict(X_test)\n",
    "\n",
    "print(\"\\n--- XGBoost (ADASYN) Performance ---\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb_adasyn))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb_adasyn))\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n--- ADASYN experiments completed in {end_time - start_time:.2f} seconds. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642dc05-0085-44fa-aa08-ce47a4bf9fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
