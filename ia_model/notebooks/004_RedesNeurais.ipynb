{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c93d92-6b75-4187-a065-ce568674b6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 07:47:46.982556: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-28 07:47:46.998629: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-28 07:47:47.492025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-28 07:47:51.672673: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-28 07:47:51.674220: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Carregando e Pré-processando os Dados ---\n",
      "--- Pré-processamento Concluído. 43 features criadas. ---\n",
      "\n",
      "--- 2. Dividindo os Dados (Treino e Teste) ---\n",
      "Tamanho do conjunto de Treino: 319\n",
      "Tamanho do conjunto de Teste:  137\n",
      "\n",
      "--- 3. Aplicando StandardScaler (Fundamental para NNs) ---\n",
      "--- Dados escalados com sucesso ---\n",
      "\n",
      "--- 4. Calculando Pesos da Classe (class_weight) ---\n",
      "Total de Treino: 319, Negativos: 224, Positivos: 95\n",
      "Peso para classe 0 (negativo): 0.7121\n",
      "Peso para classe 1 (positivo): 1.6789\n",
      "\n",
      "--- 5. Modelo 7: Construindo a Arquitetura da Rede Neural ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pontes/.cache/pypoetry/virtualenvs/ia-model-OlOOztcw-py3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-10-28 07:47:54.201412: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,953</span> (7.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,953\u001b[0m (7.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,953</span> (7.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,953\u001b[0m (7.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 6. Treinando o Modelo 7 (Rede Neural) ---\n",
      "Epoch 1/150\n",
      "8/8 - 1s - 130ms/step - accuracy: 0.5412 - loss: 0.8620 - recall: 0.3289 - val_accuracy: 0.5469 - val_loss: 0.6703 - val_recall: 0.3158\n",
      "Epoch 2/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5098 - loss: 0.8984 - recall: 0.4211 - val_accuracy: 0.5312 - val_loss: 0.6712 - val_recall: 0.2632\n",
      "Epoch 3/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5804 - loss: 0.8342 - recall: 0.4342 - val_accuracy: 0.5156 - val_loss: 0.6714 - val_recall: 0.2632\n",
      "Epoch 4/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5725 - loss: 0.8097 - recall: 0.4605 - val_accuracy: 0.5000 - val_loss: 0.6748 - val_recall: 0.2632\n",
      "Epoch 5/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5412 - loss: 0.7803 - recall: 0.5132 - val_accuracy: 0.5312 - val_loss: 0.6776 - val_recall: 0.3684\n",
      "Epoch 6/150\n",
      "8/8 - 0s - 8ms/step - accuracy: 0.5765 - loss: 0.8444 - recall: 0.4605 - val_accuracy: 0.5156 - val_loss: 0.6798 - val_recall: 0.3684\n",
      "Epoch 7/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5412 - loss: 0.8292 - recall: 0.4342 - val_accuracy: 0.5156 - val_loss: 0.6818 - val_recall: 0.3684\n",
      "Epoch 8/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5608 - loss: 0.7179 - recall: 0.5132 - val_accuracy: 0.5312 - val_loss: 0.6832 - val_recall: 0.3684\n",
      "Epoch 9/150\n",
      "8/8 - 0s - 8ms/step - accuracy: 0.5255 - loss: 0.7902 - recall: 0.5000 - val_accuracy: 0.5312 - val_loss: 0.6839 - val_recall: 0.3684\n",
      "Epoch 10/150\n",
      "8/8 - 0s - 18ms/step - accuracy: 0.5608 - loss: 0.7773 - recall: 0.5395 - val_accuracy: 0.5312 - val_loss: 0.6838 - val_recall: 0.3684\n",
      "Epoch 11/150\n",
      "8/8 - 0s - 8ms/step - accuracy: 0.5176 - loss: 0.8063 - recall: 0.5263 - val_accuracy: 0.5312 - val_loss: 0.6849 - val_recall: 0.3684\n",
      "Epoch 12/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5333 - loss: 0.7799 - recall: 0.5132 - val_accuracy: 0.5312 - val_loss: 0.6864 - val_recall: 0.3684\n",
      "Epoch 13/150\n",
      "8/8 - 0s - 18ms/step - accuracy: 0.5922 - loss: 0.7769 - recall: 0.4868 - val_accuracy: 0.5000 - val_loss: 0.6876 - val_recall: 0.3684\n",
      "Epoch 14/150\n",
      "8/8 - 0s - 9ms/step - accuracy: 0.5608 - loss: 0.7415 - recall: 0.5395 - val_accuracy: 0.5156 - val_loss: 0.6888 - val_recall: 0.3684\n",
      "Epoch 15/150\n",
      "8/8 - 0s - 8ms/step - accuracy: 0.5765 - loss: 0.7984 - recall: 0.4737 - val_accuracy: 0.5312 - val_loss: 0.6895 - val_recall: 0.4211\n",
      "Epoch 16/150\n",
      "8/8 - 0s - 8ms/step - accuracy: 0.5882 - loss: 0.6936 - recall: 0.5263 - val_accuracy: 0.5312 - val_loss: 0.6905 - val_recall: 0.4211\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Treinamento Concluído ---\n",
      "\n",
      "--- 7. Avaliando o Modelo 7 (Rede Neural) no conjunto de TESTE ---\n",
      "Acurácia (Modelo 7): 0.6788\n",
      "Recall (Modelo 7):   0.4634\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\n",
      "Relatório de Classificação (Modelo 7 - Rede Neural):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "negativo (0)       0.77      0.77      0.77        96\n",
      "positivo (1)       0.46      0.46      0.46        41\n",
      "\n",
      "    accuracy                           0.68       137\n",
      "   macro avg       0.62      0.62      0.62       137\n",
      "weighted avg       0.68      0.68      0.68       137\n",
      "\n",
      "\n",
      "Matriz de Confusão (Modelo 7 - Rede Neural):\n",
      "            [Prev. Neg] [Prev. Pos]\n",
      "[Real Neg]          74         22\n",
      "[Real Pos]          22         19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # <-- ESSENCIAL PARA REDES NEURAIS\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Configurar para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 1. Carregando e Pré-processando os Dados ---\n",
    "# ==============================================================================\n",
    "print(\"--- 1. Carregando e Pré-processando os Dados ---\")\n",
    "\n",
    "# ... (Seu código de carregamento e pré-processamento) ...\n",
    "# (Ocultado por brevidade, mas é o mesmo código que você já tem)\n",
    "# ... (Seu código de carregamento e pré-processamento) ...\n",
    "\n",
    "# Carregar o dataset\n",
    "file_path = '../data/raw/leish_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Criar cópia para processamento\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Lidar com valores ausentes (Missing)\n",
    "for col in df_processed.select_dtypes(include=['object']).columns:\n",
    "    df_processed[col] = df_processed[col].fillna('Unknown')\n",
    "\n",
    "# Codificar a variável Alvo (Target)\n",
    "target_map = {'positivo': 1, 'negativo': 0, 'Unknown': 0}\n",
    "df_processed['diagnosis'] = df_processed['diagnosis'].map(target_map).astype(int)\n",
    "\n",
    "# Separar features (X) e alvo (y)\n",
    "X_categorical = df_processed.drop('diagnosis', axis=1)\n",
    "y = df_processed['diagnosis']\n",
    "\n",
    "# Aplicar One-Hot Encoding nas features categóricas\n",
    "X_numeric = pd.get_dummies(X_categorical, drop_first=True, dtype=int)\n",
    "n_features = X_numeric.shape[1] # Salvar o número de features para a rede\n",
    "\n",
    "print(f\"--- Pré-processamento Concluído. {n_features} features criadas. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 2. Dividindo os Dados (Treino e Teste) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 2. Dividindo os Dados (Treino e Teste) ---\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_numeric, \n",
    "    y, \n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do conjunto de Treino: {X_train.shape[0]}\")\n",
    "print(f\"Tamanho do conjunto de Teste:  {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 3. [NOVO] Escalabilidade dos Dados (Scaling) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 3. Aplicando StandardScaler (Fundamental para NNs) ---\")\n",
    "\n",
    "# Redes Neurais são muito sensíveis à escala dos dados (ex: uma feature \"idade\"\n",
    "# de 0-80 não pode competir com uma feature \"sexo\" de 0-1).\n",
    "# Precisamos padronizar (média=0, desvio=1).\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ATENÇÃO: Ajustamos (fit) o scaler APENAS nos dados de TREINO\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# E APENAS transformamos (transform) os dados de TESTE com o mesmo scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"--- Dados escalados com sucesso ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 4. [NOVO] Calculando Pesos da Classe (class_weight) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 4. Calculando Pesos da Classe (class_weight) ---\")\n",
    "\n",
    "# O Keras usa os pesos de forma diferente do scikit-learn.\n",
    "# Vamos calculá-los manualmente para o `model.fit()`\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "count_neg = counts[0] # 224\n",
    "count_pos = counts[1] # 95\n",
    "total = count_neg + count_pos # 319\n",
    "\n",
    "# Fórmula para calcular pesos (Manual)\n",
    "weight_for_0 = (1 / count_neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / count_pos) * (total / 2.0)\n",
    "\n",
    "# Criar o dicionário de pesos\n",
    "class_weight_dict = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(f\"Total de Treino: {total}, Negativos: {count_neg}, Positivos: {count_pos}\")\n",
    "print(f\"Peso para classe 0 (negativo): {weight_for_0:.4f}\")\n",
    "print(f\"Peso para classe 1 (positivo): {weight_for_1:.4f}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 5. Modelo 7: Construindo a Rede Neural (Keras) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 5. Modelo 7: Construindo a Arquitetura da Rede Neural ---\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Camada de Entrada (Input) e Primeira Camada Oculta (Hidden)\n",
    "# 'input_shape' deve ser o número de features\n",
    "# 'relu' é a função de ativação padrão\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_features,)))\n",
    "# Camada de Dropout para combater overfitting\n",
    "model.add(Dropout(0.5)) # \"Desliga\" 50% dos neurônios nesta camada\n",
    "\n",
    "# Segunda Camada Oculta\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5)) # Mais dropout\n",
    "\n",
    "# Camada de Saída (Output)\n",
    "# 'sigmoid' é usado para classificação binária (retorna um valor entre 0 e 1)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "# 'adam' é um otimizador robusto\n",
    "# 'binary_crossentropy' é a função de perda correta para 'sigmoid'\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(name='recall')] # Vamos monitorar o Recall!\n",
    ")\n",
    "\n",
    "# Mostrar um resumo da arquitetura\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 6. Treinando o Modelo 7 (Rede Neural) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 6. Treinando o Modelo 7 (Rede Neural) ---\")\n",
    "\n",
    "# Callback de EarlyStopping:\n",
    "# Monitora 'val_loss' (perda nos dados de validação)\n",
    "# 'patience=15': Para o treino se a 'val_loss' não melhorar por 15 épocas seguidas\n",
    "# 'restore_best_weights=True': Salva o modelo do melhor ponto (não o último)\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=15, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "# 'validation_split=0.2': Separa 20% dos dados de TREINO para validar o overfitting\n",
    "# 'class_weight': Nosso dicionário de pesos!\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=150,                 # Número máximo de épocas\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopper],\n",
    "    class_weight=class_weight_dict, # <-- APLICANDO O BALANCEAMENTO\n",
    "    verbose=2                   # Mostra o log de treino\n",
    ")\n",
    "\n",
    "print(\"--- Treinamento Concluído ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 7. Avaliando o Modelo 7 (Rede Neural) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 7. Avaliando o Modelo 7 (Rede Neural) no conjunto de TESTE ---\")\n",
    "\n",
    "# Avaliar a perda e métricas finais nos dados de TESTE (escalados)\n",
    "test_loss, test_accuracy, test_recall = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Acurácia (Modelo 7): {test_accuracy:.4f}\")\n",
    "print(f\"Recall (Modelo 7):   {test_recall:.4f}\") # Recall na classe positiva\n",
    "\n",
    "# Obter as previsões\n",
    "# As previsões são probabilidades (ex: 0.15, 0.88, 0.45)\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "\n",
    "# Converter probabilidades em classes (0 ou 1)\n",
    "# Usamos o limiar (threshold) padrão de 0.5\n",
    "y_pred_nn = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "# Exibir Relatório de Classificação\n",
    "print(\"\\nRelatório de Classificação (Modelo 7 - Rede Neural):\")\n",
    "print(classification_report(y_test, y_pred_nn, target_names=['negativo (0)', 'positivo (1)']))\n",
    "\n",
    "# Exibir Matriz de Confusão\n",
    "print(\"\\nMatriz de Confusão (Modelo 7 - Rede Neural):\")\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "print(f\"            [Prev. Neg] [Prev. Pos]\")\n",
    "print(f\"[Real Neg]  {cm_nn[0][0]:>10} {cm_nn[0][1]:>10}\")\n",
    "print(f\"[Real Pos]  {cm_nn[1][0]:>10} {cm_nn[1][1]:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95d9d5-0631-467d-aaae-f35c1ff630be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
