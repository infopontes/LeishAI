{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3030b13d-7df8-4980-a66d-d063fe6bc816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Carregando e Pré-processando os Dados ---\n",
      "--- Pré-processamento Concluído. 43 features criadas. ---\n",
      "\n",
      "--- 2. Dividindo os Dados (Treino e Teste) ---\n",
      "Tamanho do conjunto de Treino: 319\n",
      "Tamanho do conjunto de Teste:  137\n",
      "\n",
      "--- 3. Aplicando StandardScaler (ANOS do SMOTE) ---\n",
      "--- Dados escalados com sucesso ---\n",
      "\n",
      "--- 4. Modelo 9: Aplicando SMOTE para balancear os dados de TREINO ---\n",
      "Distribuição de classes ANTES do SMOTE: {np.int64(0): np.int64(224), np.int64(1): np.int64(95)}\n",
      "Distribuição de classes DEPOIS do SMOTE: {np.int64(0): np.int64(224), np.int64(1): np.int64(224)}\n",
      "\n",
      "--- 5. Treinando a Regressão Logística com dados do SMOTE ---\n",
      "--- Treinamento do Modelo 9 Concluído ---\n",
      "\n",
      "--- 6. Avaliando o Modelo 9 (LR + SMOTE) ---\n",
      "Acurácia (Modelo 9 - LR + SMOTE): 0.6204\n",
      "\n",
      "Relatório de Classificação (Modelo 9 - LR + SMOTE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "negativo (0)       0.78      0.64      0.70        96\n",
      "positivo (1)       0.41      0.59      0.48        41\n",
      "\n",
      "    accuracy                           0.62       137\n",
      "   macro avg       0.59      0.61      0.59       137\n",
      "weighted avg       0.67      0.62      0.63       137\n",
      "\n",
      "\n",
      "Matriz de Confusão (Modelo 9 - LR + SMOTE):\n",
      "            [Prev. Neg] [Prev. Pos]\n",
      "[Real Neg]          61         35\n",
      "[Real Pos]          17         24\n",
      "\n",
      "\n",
      "--- 7. BÔNUS: Coeficientes da Regressão Logística (Treinada com SMOTE) ---\n",
      "\n",
      "--- Top 10 Features que MAIS INDICAM 'POSITIVO' (Modelo 9) ---\n",
      "                               Feature  Coefficient (Peso)\n",
      "33                 breed_name_PIT BULL            0.335206\n",
      "20  muzzle_lip_depigmentation_presente            0.314735\n",
      "15    conjunctivitis_Conjuntivite Leve            0.312266\n",
      "29               breed_name_Lhasa Apso            0.297244\n",
      "9   mucosa_color_levemente_hipercorada            0.269180\n",
      "35                   breed_name_Poodle            0.232145\n",
      "24                breed_name_Dachshund            0.220523\n",
      "34                 breed_name_Pinscher            0.220366\n",
      "17                   bleeding_presente            0.194059\n",
      "7                          coat_normal            0.143233\n",
      "\n",
      "--- Top 10 Features que MAIS INDICAM 'NEGATIVO' (Modelo 9) ---\n",
      "                  Feature  Coefficient (Peso)\n",
      "12     lymph_nodes_normal           -0.749636\n",
      "25     breed_name_Dálmata           -0.437788\n",
      "36  breed_name_Rottweiler           -0.321756\n",
      "3      ectoparasites_leve           -0.313519\n",
      "26        breed_name_Fila           -0.296694\n",
      "39     breed_name_Shipdog           -0.246899\n",
      "38     breed_name_Sharpei           -0.212449\n",
      "41  breed_name_Weimaraner           -0.211322\n",
      "1      general_state_ruim           -0.198729\n",
      "23  breed_name_DOG ALEMÃO           -0.158640\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE # <-- Importando o SMOTE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 1. Carregando e Pré-processando os Dados ---\n",
    "# ==============================================================================\n",
    "print(\"--- 1. Carregando e Pré-processando os Dados ---\")\n",
    "\n",
    "# ... (Seu código de carregamento e pré-processamento) ...\n",
    "# (Ocultado por brevidade, mas é o mesmo código que você já tem)\n",
    "# ... (Seu código de carregamento e pré-processamento) ...\n",
    "\n",
    "# Carregar o dataset\n",
    "file_path = '../data/raw/leish_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Criar cópia para processamento\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Lidar com valores ausentes (Missing)\n",
    "for col in df_processed.select_dtypes(include=['object']).columns:\n",
    "    df_processed[col] = df_processed[col].fillna('Unknown')\n",
    "\n",
    "# Codificar a variável Alvo (Target)\n",
    "target_map = {'positivo': 1, 'negativo': 0, 'Unknown': 0}\n",
    "df_processed['diagnosis'] = df_processed['diagnosis'].map(target_map).astype(int)\n",
    "\n",
    "# Separar features (X) e alvo (y)\n",
    "X_categorical = df_processed.drop('diagnosis', axis=1)\n",
    "y = df_processed['diagnosis']\n",
    "\n",
    "# Aplicar One-Hot Encoding nas features categóricas\n",
    "X_numeric = pd.get_dummies(X_categorical, drop_first=True, dtype=int)\n",
    "feature_names = X_numeric.columns.tolist() \n",
    "\n",
    "print(f\"--- Pré-processamento Concluído. {len(feature_names)} features criadas. ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 2. Dividindo os Dados (Treino e Teste) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 2. Dividindo os Dados (Treino e Teste) ---\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_numeric, \n",
    "    y, \n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do conjunto de Treino: {X_train.shape[0]}\")\n",
    "print(f\"Tamanho do conjunto de Teste:  {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 3. Aplicando StandardScaler (Fundamental) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 3. Aplicando StandardScaler (ANOS do SMOTE) ---\")\n",
    "\n",
    "# É importante escalar os dados ANTES de aplicar o SMOTE,\n",
    "# para que o SMOTE calcule as \"distâncias\" em um espaço padronizado.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar o scaler APENAS nos dados de TREINO\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar os dados de TESTE com o mesmo scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"--- Dados escalados com sucesso ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 4. Modelo 9: Aplicando SMOTE ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 4. Modelo 9: Aplicando SMOTE para balancear os dados de TREINO ---\")\n",
    "\n",
    "# Contar as classes ANTES do SMOTE\n",
    "unique_before, counts_before = np.unique(y_train, return_counts=True)\n",
    "print(f\"Distribuição de classes ANTES do SMOTE: {dict(zip(unique_before, counts_before))}\")\n",
    "\n",
    "# Inicializar o SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# Aplicar SMOTE. IMPORTANTE: Aplicar APENAS nos dados de TREINO (já escalados)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Contar as classes DEPOIS do SMOTE\n",
    "unique_after, counts_after = np.unique(y_train_smote, return_counts=True)\n",
    "print(f\"Distribuição de classes DEPOIS do SMOTE: {dict(zip(unique_after, counts_after))}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 5. Treinando a Regressão Logística com dados do SMOTE ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 5. Treinando a Regressão Logística com dados do SMOTE ---\")\n",
    "\n",
    "# Inicializar o modelo\n",
    "# ATENÇÃO: NÃO usamos mais class_weight='balanced', \n",
    "# pois os dados de treino JÁ ESTÃO balanceados.\n",
    "lr_smote_classifier = LogisticRegression(\n",
    "    random_state=42,\n",
    "    solver='liblinear' \n",
    ")\n",
    "\n",
    "# Treinar o modelo nos dados de treino (escalados E balanceados)\n",
    "lr_smote_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(\"--- Treinamento do Modelo 9 Concluído ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 6. Avaliando o Modelo 9 (LR + SMOTE) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 6. Avaliando o Modelo 9 (LR + SMOTE) ---\")\n",
    "\n",
    "# Fazer previsões no conjunto de TESTE (escalado, mas original)\n",
    "y_pred_lr_smote = lr_smote_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calcular a Acurácia\n",
    "print(f\"Acurácia (Modelo 9 - LR + SMOTE): {accuracy_score(y_test, y_pred_lr_smote):.4f}\")\n",
    "\n",
    "# Exibir Relatório de Classificação\n",
    "print(\"\\nRelatório de Classificação (Modelo 9 - LR + SMOTE):\")\n",
    "print(classification_report(y_test, y_pred_lr_smote, target_names=['negativo (0)', 'positivo (1)']))\n",
    "\n",
    "# Exibir Matriz de Confusão\n",
    "print(\"\\nMatriz de Confusão (Modelo 9 - LR + SMOTE):\")\n",
    "cm_lr_smote = confusion_matrix(y_test, y_pred_lr_smote)\n",
    "print(f\"            [Prev. Neg] [Prev. Pos]\")\n",
    "print(f\"[Real Neg]  {cm_lr_smote[0][0]:>10} {cm_lr_smote[0][1]:>10}\")\n",
    "print(f\"[Real Pos]  {cm_lr_smote[1][0]:>10} {cm_lr_smote[1][1]:>10}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 7. BÔNUS: Coeficientes do Modelo (SMOTE) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n\\n--- 7. BÔNUS: Coeficientes da Regressão Logística (Treinada com SMOTE) ---\")\n",
    "\n",
    "# Extrair os coeficientes (pesos) que o modelo aprendeu\n",
    "coefficients = lr_smote_classifier.coef_[0]\n",
    "\n",
    "# Criar um DataFrame para visualizar os coeficientes\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient (Peso)': coefficients\n",
    "})\n",
    "\n",
    "# Ordenar pelos valores\n",
    "coef_df = coef_df.sort_values(by='Coefficient (Peso)', ascending=False)\n",
    "\n",
    "print(\"\\n--- Top 10 Features que MAIS INDICAM 'POSITIVO' (Modelo 9) ---\")\n",
    "print(coef_df.head(10))\n",
    "\n",
    "print(\"\\n--- Top 10 Features que MAIS INDICAM 'NEGATIVO' (Modelo 9) ---\")\n",
    "print(coef_df.tail(10).sort_values(by='Coefficient (Peso)', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f49584-65cf-423a-85a5-3e892c52594f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
