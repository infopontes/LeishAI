# ğŸ§¬ LeishAI Project ğŸ”¬ğŸ¾

**LeishAI** aims to provide an AI-powered tool to assist veterinarians in the diagnosis of canine leishmaniasis based on clinical signs.  
This repository contains the **backend API** and the **machine learning model development** components.

---

## âœ¨ Features

### ğŸ§© Backend (FastAPI API)

- **RESTful API:** Provides endpoints for managing core entities:
  - Users & Authentication (JWT-based)
  - Roles & Permissions (Admin, Veterinarian, Coordinator)
  - Owners
  - Breeds
  - Animals
  - Clinical Assessments
- **AI Prediction Endpoint:** Integrates the trained machine learning model via a `/predict` endpoint to provide diagnosis predictions based on input clinical data and confidence scores.
- **Data Validation:** Uses Pydantic for robust request and response validation.
- **Database Management:** SQLAlchemy ORM with PostgreSQL and Alembic for schema migrations.
- **Asynchronous:** Built with FastAPI for high performance.
- **Security:**
  - Password hashing (`passlib` with `bcrypt`).
  - Role-Based Access Control (RBAC).
  - Rate limiting (`slowapi`) on authentication and registration.
  - CORS configured for frontend integration.
- **Testing:** Comprehensive Pytest suite with ~94% code coverage.
- **Dependency Management:** Managed with Poetry.
- **Data Seeding:** Includes scripts to populate the database with initial roles, users, breeds, and imported CSV data.
- **Dockerized Database:** Easy setup with Docker Compose.

---

### ğŸ¤– IA Model (Machine Learning)

- **Data Pipeline:** Extracts, cleans, and preprocesses data from the backend PostgreSQL database.
- **Exploratory Data Analysis (EDA):** Jupyter notebooks for feature visualization and distribution analysis.
- **Preprocessing:** Handles missing values and performs One-Hot Encoding for categorical data.
- **Model Experimentation:** Trained and evaluated:
  - Logistic Regression
  - Random Forest
  - XGBoost
  - Support Vector Machine (SVM)
- **Imbalanced Data Handling:** Explored `class_weight`, SMOTE, and RandomUnderSampler.
- **Hyperparameter Tuning:** Used `GridSearchCV`, focusing on the **recall** metric.
- **Final Model:** **Balanced Logistic Regression** selected as best-performing model.
- **Artifact Saving:** Saves `.joblib` model and training columns for consistent inference.
- **Dependency Management:** Managed with Poetry.

---

## ğŸ› ï¸ Tech Stack

| Area | Technologies |
|------|---------------|
| **Backend** | Python, FastAPI, SQLAlchemy, Alembic, PostgreSQL, Docker, Poetry, Pydantic, Passlib, SlowAPI |
| **Machine Learning** | Python, Pandas, Scikit-learn, XGBoost, Imbalanced-learn, Jupyter Lab, Joblib, Poetry |
| **Testing** | Pytest, Pytest-Cov |
| **Linting/Formatting** | Ruff |

---

## ğŸ“‚ Project Structure

```
ğŸ“¦ Project Root
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ backend/                        # FastAPI backend project
â”‚   â”œâ”€â”€ alembic/                    # Database migrations (Alembic)
â”‚   â”‚   â”œâ”€â”€ env.py
â”‚   â”‚   â”œâ”€â”€ script.py.mako
â”‚   â”‚   â””â”€â”€ versions/               # Migration scripts
â”‚   â”‚       â”œâ”€â”€ 53bf8d2f70e6_create_user_table.py
â”‚   â”‚       â”œâ”€â”€ 15b1870dd74c_add_owner_and_animal_models.py
â”‚   â”‚       â”œâ”€â”€ ...
â”‚   â”‚       â””â”€â”€ fe8353f6c31b_add_full_name_and_institution_to_user_.py
â”‚   â”‚
â”‚   â”œâ”€â”€ alembic.ini                 # Alembic configuration file
â”‚   â”œâ”€â”€ dataset.csv                 # Dataset used for testing or seeding
â”‚   â”œâ”€â”€ docker-compose.yml          # Docker setup for backend services
â”‚   â”œâ”€â”€ ml_models/                  # Pre-trained ML models
â”‚   â”‚   â”œâ”€â”€ leish_model_v1.joblib
â”‚   â”‚   â””â”€â”€ training_columns_v1.joblib
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/                    # Database seeding and utilities
â”‚   â”‚   â”œâ”€â”€ seed.py
â”‚   â”‚   â””â”€â”€ seeds/
â”‚   â”‚       â”œâ”€â”€ seed_breeds.py
â”‚   â”‚       â”œâ”€â”€ seed_from_csv.py
â”‚   â”‚       â””â”€â”€ seed_users.py
â”‚   â”‚
â”‚   â”œâ”€â”€ src/                        # Core backend source code
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ api/v1/                 # API routes (versioned)
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router_animals.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router_assessments.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router_auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router_breeds.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router_owners.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router_prediction.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router_roles.py
â”‚   â”‚   â”‚   â””â”€â”€ router_users.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/                   # Core configurations and security
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â”œâ”€â”€ limiter.py
â”‚   â”‚   â”‚   â””â”€â”€ security.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ db/                     # Database access and models
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â”‚   â”œâ”€â”€ crud/               # CRUD operations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ crud_animal.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ crud_assessment.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ crud_breed.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ crud_owner.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ crud_role.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ crud_user.py
â”‚   â”‚   â”‚   â””â”€â”€ models/             # SQLAlchemy models
â”‚   â”‚   â”‚       â”œâ”€â”€ animal.py
â”‚   â”‚   â”‚       â”œâ”€â”€ assessment.py
â”‚   â”‚   â”‚       â”œâ”€â”€ base.py
â”‚   â”‚   â”‚       â”œâ”€â”€ breed.py
â”‚   â”‚   â”‚       â”œâ”€â”€ enums.py
â”‚   â”‚   â”‚       â”œâ”€â”€ owner.py
â”‚   â”‚   â”‚       â”œâ”€â”€ role.py
â”‚   â”‚   â”‚       â””â”€â”€ user.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ml/                     # ML service integration
â”‚   â”‚   â”‚   â””â”€â”€ prediction_service.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ schemas/                # Pydantic schemas
â”‚   â”‚       â”œâ”€â”€ animal.py
â”‚   â”‚       â”œâ”€â”€ assessment.py
â”‚   â”‚       â”œâ”€â”€ breed.py
â”‚   â”‚       â”œâ”€â”€ owner.py
â”‚   â”‚       â”œâ”€â”€ prediction.py
â”‚   â”‚       â”œâ”€â”€ role.py
â”‚   â”‚       â””â”€â”€ user.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                      # Unit and integration tests
â”‚   â”‚   â”œâ”€â”€ conftest.py
â”‚   â”‚   â”œâ”€â”€ test_main.py
â”‚   â”‚   â”œâ”€â”€ test_users_db.py
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ test_animals_api.py
â”‚   â”‚       â”œâ”€â”€ test_assessments_api.py
â”‚   â”‚       â”œâ”€â”€ test_breeds_api.py
â”‚   â”‚       â”œâ”€â”€ test_owners_api.py
â”‚   â”‚       â”œâ”€â”€ test_prediction_api.py
â”‚   â”‚       â”œâ”€â”€ test_users_api.py
â”‚   â”‚       â””â”€â”€ test_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ poetry.lock
â”‚   â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ frontend/                       # Placeholder for frontend project
â”‚
â””â”€â”€ ia_model/                       # Machine Learning workspace
    â”œâ”€â”€ data/                       # Raw datasets
    â”‚   â””â”€â”€ raw/leish_dataset.csv
    â”‚
    â”œâ”€â”€ models/                     # Trained ML models
    â”‚   â”œâ”€â”€ leish_model_v1.joblib
    â”‚   â””â”€â”€ training_columns_v1.joblib
    â”‚
    â”œâ”€â”€ notebooks/                  # Jupyter notebooks (EDA, training, etc.)
    â”‚   â”œâ”€â”€ 01-EDA.ipynb
    â”‚   â”œâ”€â”€ 02-Model_Training.ipynb
    â”‚   â”œâ”€â”€ 03-Advanced_Imbalanced_Learning.ipynb
    â”‚   â”œâ”€â”€ 04-Undersampling_Experiment.ipynb
    â”‚   â””â”€â”€ 05-SVM_Experiments.ipynb
    â”‚
    â”œâ”€â”€ src/                        # Python modules for ML workflow
    â”‚   â”œâ”€â”€ data/data_loader.py
    â”‚   â”œâ”€â”€ models/
    â”‚   â””â”€â”€ preprocessing/
    â”‚
    â”œâ”€â”€ scripts/                    # Utility scripts for data/model handling
    â”œâ”€â”€ poetry.lock
    â””â”€â”€ pyproject.toml
```

---

## ğŸš€ Getting Started

### ğŸ§° Prerequisites

- Python >= 3.12  
- Poetry (`pip install poetry`)  
- Docker & Docker Compose  

---

### âš™ï¸ Setup

1. **Clone the repository**
   ```bash
   git clone <your-repository-url>
   cd LeishAI
   ```

2. **Setup Backend**
   ```bash
   cd backend
   poetry install
   cp .env.example .env
   # Edit .env with your PostgreSQL credentials
   ```

3. **Setup IA Model**
   ```bash
   cd ../ia_model
   poetry install
   ```

---

### â–¶ï¸ Running the Application

1. **Start the Database**
   ```bash
   cd backend
   docker-compose up -d
   ```

2. **Apply Migrations**
   ```bash
   poetry run alembic upgrade head
   ```

3. **Seed the Database**
   ```bash
   poetry run task seed
   ```

4. **Run the Backend Server**
   ```bash
   poetry run task run
   ```
   The API will be available at:  
   ğŸ”— `http://127.0.0.1:8000`  
   Swagger Docs: `http://127.0.0.1:8000/docs`

---

## âœ… Running Tests

To run all backend tests with coverage:

```bash
cd backend
poetry run task test
```

---

## ğŸ’¾ Database Migrations

Database schema changes are managed using **Alembic**.  
See: [`backend/alembic/README.md`](backend/alembic/README.md)

---

## ğŸŒ± Data Seeding

The backend includes scripts to populate the database with initial roles, users, breeds, and dataset imports.

```bash
cd backend
poetry run task seed
```

---

## ğŸ§  Machine Learning Workflow

Located in `ia_model/`:

1. **Extract Data**
   ```bash
   poetry run task loader
   ```
   Saves data to:  
   `ia_model/data/raw/leish_dataset.csv`

2. **Explore & Train**
   ```bash
   poetry run task notebook
   ```
   Open Jupyter Lab and explore:
   - `01-EDA.ipynb`
   - `02-Model_Training.ipynb`

   âœ… Final selected model: **Balanced Logistic Regression**

---

## ğŸ“š API Documentation

Once running, interactive documentation is available at:  
ğŸ”— [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

**LeishAI** â€” Artificial Intelligence assisting veterinary diagnostics ğŸ§ ğŸ¶  
Developed with â¤ï¸ using **FastAPI**, **Poetry**, and **Scikit-learn**.
